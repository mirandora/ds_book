{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ecd3785",
   "metadata": {},
   "source": [
    "#### 本notebookは『データサイエンスの無駄遣い』（[著]篠田裕之, 翔泳社, 2021）のサンプルコードとなります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998df8e9",
   "metadata": {},
   "source": [
    "## chapter2：多⾯的な⾃分と向き合うためのチャットボット"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905e051a",
   "metadata": {},
   "source": [
    "### 実行検証環境"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4667484",
   "metadata": {},
   "source": [
    "・Python (3.9.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cc52bb",
   "metadata": {},
   "source": [
    "・pandas (1.2.4)<br>\n",
    "・beautifulsoup4 (4.9.3)<br>\n",
    "・urllib3 (1.26.4)<br>\n",
    "・janome (0.4.1)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9538bc",
   "metadata": {},
   "source": [
    "### 事前準備"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04eaf4e7",
   "metadata": {},
   "source": [
    "・本書の手順に応じて./dataフォルダにFacebook、LINEのチャット履歴データを保存しておく。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136ae1e0",
   "metadata": {},
   "source": [
    "### パッケージのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bf2a449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c164eee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from janome.tokenizer import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "194c3129",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6a2436",
   "metadata": {},
   "source": [
    "### データ取得・前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc93a10d",
   "metadata": {},
   "source": [
    "chapter1のコードと同様にLINEとfacebookのデータを取得・前処理（ただし統計量の計算は不要のためコメントアウト）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "830b0f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_line_message_df(name, my_name, text):\n",
    "    f = open(text, 'r', encoding='utf-8')\n",
    "    line_data = f.readlines()\n",
    "    f.close()    \n",
    "    \n",
    "    tmp_day = \"\"\n",
    "    tmp_time = \"\"\n",
    "    tmp_from = \"\"\n",
    "    tmp_text = \"\"\n",
    "\n",
    "    daytime_list = []\n",
    "    from_list = []\n",
    "    text_list = []\n",
    "\n",
    "    count = 0\n",
    "    \n",
    "    for text in line_data:        \n",
    "        if (\"とのトーク履歴\" in text) or (\"保存日時\" in text):\n",
    "            continue\n",
    "\n",
    "        if len(text) == 14:\n",
    "            if (text[4] == \"/\") and (text[7] == \"/\") and (text[10] == \"(\"):\n",
    "                #もしメッセージが格納されていれば前の時刻までのメッセージを格納\n",
    "                if len(tmp_text) > 1:\n",
    "                    daytime_list.append(tmp_day + \" \" + tmp_time)\n",
    "                    from_list.append(tmp_from)                \n",
    "                    tmp_text = tmp_text.replace(\"\\n\",\"\")                \n",
    "                    text_list.append(tmp_text)\n",
    "                    \n",
    "                tmp_text = \"\"                    \n",
    "                tmp_day = text[:-4]    \n",
    "                continue\n",
    "\n",
    "        if len(text) > 5:\n",
    "            if text[2] == \":\" and text[5] == '\\t':\n",
    "                #もしメッセージが格納されていれば前の時刻までのメッセージを格納\n",
    "                if len(tmp_text) > 1:\n",
    "                    daytime_list.append(tmp_day + \" \" + tmp_time)\n",
    "                    from_list.append(tmp_from)                \n",
    "                    tmp_text = tmp_text.replace(\"\\n\",\"\")                \n",
    "                    text_list.append(tmp_text)\n",
    "                \n",
    "                split_text = text.split(\"\\t\")\n",
    "                tmp_time = split_text[0]\n",
    "                tmp_from = split_text[1]\n",
    "                tmp_text = split_text[2]                \n",
    "                continue\n",
    "                                \n",
    "        #時刻付きの行ではない（前の時刻のメッセージの続きなら前のテキストに続ける）\n",
    "        tmp_text = tmp_text + text\n",
    "        \n",
    "    #最後のメッセージを加える\n",
    "    daytime_list.append(tmp_day + \" \" + tmp_time)\n",
    "    from_list.append(tmp_from)                \n",
    "    tmp_text = tmp_text.replace(\"\\n\",\"\")                \n",
    "    text_list.append(tmp_text)\n",
    "        \n",
    "    tmp_df = pd.DataFrame({\n",
    "                                'from':from_list, \n",
    "                                'text':text_list,\n",
    "                                'time':daytime_list    \n",
    "                    })\n",
    "    \n",
    "    tmp_df[\"thread\"] = name\n",
    "            \n",
    "    #本章では不要のためコメントアウト\n",
    "    #tmp_df = get_chat_convert_df(tmp_df, name, my_name)\n",
    "    \n",
    "    #最後の行は削除（スレッドの最後は返信がないため）\n",
    "    tmp_df = tmp_df[:-1]\n",
    "    \n",
    "    return tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3ca2056",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_message_df(name, my_name, url_list):\n",
    "    for i in range(len(url_list)):\n",
    "        #print(url_list[i])\n",
    "        #print(i)\n",
    "        html = open(url_list[i], 'r', encoding='utf-8')\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        from_classes = soup.find_all(class_=\"_3-96 _2pio _2lek _2lel\")\n",
    "        text_classes = soup.find_all(class_=\"_3-96 _2let\")\n",
    "        time_classes = soup.find_all(class_=\"_3-94 _2lem\")    \n",
    "\n",
    "        from_list = []\n",
    "        text_list = []\n",
    "        time_list = []\n",
    "\n",
    "        for k in range(len(from_classes)):\n",
    "                from_list.append(from_classes[k].text)\n",
    "                text_list.append(text_classes[k].text)\n",
    "                time_list.append(time_classes[k].text)\n",
    "\n",
    "        if i == 0:\n",
    "            tmp_df = pd.DataFrame({\n",
    "                            'from':from_list, \n",
    "                            'text':text_list,\n",
    "                            'time':time_list\n",
    "                             })        \n",
    "        else:\n",
    "            tmp_df2 = pd.DataFrame({\n",
    "                            'from':from_list, \n",
    "                            'text':text_list,\n",
    "                            'time':time_list\n",
    "                             })        \n",
    "            \n",
    "            tmp_df = pd.concat([tmp_df, tmp_df2]).reset_index(drop=True)            \n",
    "                        \n",
    "    tmp_df[\"thread\"] = name\n",
    "            \n",
    "    #本章では不要のためコメントアウト\n",
    "    #tmp_df = get_chat_convert_df(tmp_df, name, my_name)\n",
    "    \n",
    "    #最後の行は削除（スレッドの最後は返信がないため）\n",
    "    tmp_df = tmp_df[:-1]\n",
    "    \n",
    "    return tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2670af9",
   "metadata": {},
   "source": [
    "#### LINEとFacebookのチャットデータの取得（./dataフォルダ内に分析したいチャット相手のログを取得しておく）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff8657a",
   "metadata": {},
   "source": [
    "※GitHub(https://github.com/mirandora/ds_book/tree/main/2_1) に公開しているものはコード動作確認用に作成した架空のダミーデータとなります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a298b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_A_df = make_line_message_df(\"UserA\",\"HiroyukiS\",\"./data/user_a.txt\") #LINEデータの場合\n",
    "user_B_df = make_message_df(\"user_b\",\"Hiroyuki Shinoda\", [\"./data/user_b.html\"]) #Facebookデータの場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "266df982",
   "metadata": {},
   "outputs": [],
   "source": [
    "#自分の発言ログのテキストのみを取得（自分のLINEアカウント名が\"HiroyukiS\"、facebookアカウント名が\"Hiroyuki Shinoda\"の場合）\n",
    "selfchat_A = user_A_df[user_A_df[\"from\"]==\"HiroyukiS\"].reset_index(drop=True).text\n",
    "selfchat_B = user_B_df[user_B_df[\"from\"]==\"Hiroyuki Shinoda\"].reset_index(drop=True).text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57947683",
   "metadata": {},
   "source": [
    "### 形態素解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5b52632",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dc9e4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "むしろ\t副詞,一般,*,*,*,*,むしろ,ムシロ,ムシロ\n",
      "その\t連体詞,*,*,*,*,*,その,ソノ,ソノ\n",
      "ストーリー\t名詞,一般,*,*,*,*,ストーリー,ストーリー,ストーリー\n",
      "は\t助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
      "君\t名詞,代名詞,一般,*,*,*,君,キミ,キミ\n",
      "が\t助詞,格助詞,一般,*,*,*,が,ガ,ガ\n",
      "つくり\t動詞,自立,*,*,五段・ラ行,連用形,つくる,ツクリ,ツクリ\n",
      "たまえ\t動詞,自立,*,*,五段・ワ行促音便,命令ｅ,たまう,タマエ,タマエ\n",
      "。\t記号,句点,*,*,*,*,。,。,。\n"
     ]
    }
   ],
   "source": [
    "text = \"むしろそのストーリーは君がつくりたまえ。\"\n",
    "for token in tokenizer.tokenize(text):\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c0095d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "むしろ\n",
      "その\n",
      "ストーリー\n",
      "は\n",
      "君\n",
      "が\n",
      "つくり\n",
      "たまえ\n",
      "。\n"
     ]
    }
   ],
   "source": [
    "for token in tokenizer.tokenize(text):\n",
    "    print(token.surface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "384bbd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list_A = []\n",
    "for i in range(len(selfchat_A)):\n",
    "    for token in tokenizer.tokenize(selfchat_A[i]):\n",
    "        word_list_A.append(token.surface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "312ea02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df_A = pd.DataFrame(word_list_A)\n",
    "word_df_A.columns = [\"word\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a347d734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>。</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>、</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>？</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ゲーム</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>て</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  index  word\n",
       "0     。    21\n",
       "1     、    14\n",
       "2     ？    10\n",
       "3   ゲーム    10\n",
       "4     て     9"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_df_A.word.value_counts().reset_index().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be2028f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list_A = []\n",
    "for i in range(len(selfchat_A)):\n",
    "    for token in tokenizer.tokenize(selfchat_A[i]):\n",
    "        if (token.part_of_speech.split(',')[0] != '記号') and (token.part_of_speech.split(',')[0] != '助詞') and (token.part_of_speech.split(',')[0] != '助動詞'):\n",
    "            word_list_A.append(token.surface)\n",
    "\n",
    "word_df_A = pd.DataFrame(word_list_A)\n",
    "word_df_A.columns = [\"word\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a396ba7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ゲーム</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>し</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ほんと</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>いる</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>いや</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  index  word\n",
       "0   ゲーム    10\n",
       "1     し     8\n",
       "2   ほんと     5\n",
       "3    いる     4\n",
       "4    いや     4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_df_A.word.value_counts().reset_index().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d442b441",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df_A = word_df_A[(word_df_A[\"word\"] != \":\") & (word_df_A[\"word\"] != \"00\")].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f7849ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ゲーム</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>し</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ほんと</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>いや</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>いる</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  index  word\n",
       "0   ゲーム    10\n",
       "1     し     8\n",
       "2   ほんと     5\n",
       "3    いや     4\n",
       "4    いる     4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_df_A.word.value_counts().reset_index().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e724c2ff",
   "metadata": {},
   "source": [
    "### テキストデータのマルコフ連鎖"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96690314",
   "metadata": {},
   "source": [
    "ストップワードを定義する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24956d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [\"。\", \"！\", \"!\", \" \", \"？\", \"?\", \")\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10774440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(text_list, n_size = 1):\n",
    "    model = {}\n",
    "    for text in text_list:\n",
    "        queue = deque([], n_size)\n",
    "        queue.append(\"[BOS]\")\n",
    "        \n",
    "        for i, token in enumerate(tokenizer.tokenize(text)):\n",
    "            key = tuple(queue)\n",
    "            \n",
    "            if key not in model:\n",
    "                model[key] = []\n",
    "                \n",
    "            model[key].append(token.surface)            \n",
    "            queue.append(token.surface)\n",
    "            \n",
    "            #ストップワードあるいは最後のtokenだった場合\n",
    "            if (token.surface in stop_words) or (i == (len(list(tokenizer.tokenize(text)))-1)):                \n",
    "                key = tuple(queue)\n",
    "\n",
    "                if key not in model:\n",
    "                    model[key] = []\n",
    "                model[key].append(\"[EOS]\")\n",
    "                \n",
    "                #もし最後のtokenではない場合はqueueをリセットして続行。\n",
    "                if (i != (len(list(tokenizer.tokenize(text)))-1)):\n",
    "                    queue = deque([], n_size)\n",
    "                    queue.append(\"[BOS]\")                \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c80ecbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "self_model_A = make_model(selfchat_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "150f6e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sentence(model, max_sentence_num=3, seed=\"[BOS]\", n_size=1):    \n",
    "    sentence_count = 0\n",
    "    c_token_list = []\n",
    "    key_candidates = []\n",
    "\n",
    "    #もしseedがBOSではない場合、まずは形態素解析。\n",
    "    if seed != \"[BOS]\":\n",
    "        #記号、助詞、助動詞いずれでもなければ文章生成元token候補リストに入れる。\n",
    "        for token in tokenizer.tokenize(seed):\n",
    "            if (token.part_of_speech.split(',')[0] != '記号') and (token.part_of_speech.split(',')[0] != '助詞') and (token.part_of_speech.split(',')[0] != '助動詞'):    \n",
    "                c_token_list.append(token.surface)\n",
    "                \n",
    "        while(len(c_token_list) > 0):\n",
    "            c_rand = random.randrange(len(c_token_list))        \n",
    "            key_candidates = [key for key in model if key[0] == c_token_list[c_rand]] \n",
    "            if len(key_candidates) > 0:\n",
    "                break\n",
    "            c_token_list.pop(c_rand)        \n",
    "    \n",
    "    else:\n",
    "        #seedから始まるkeyを取得\n",
    "        key_candidates = [key for key in model if key[0] == seed]    \n",
    "    \n",
    "    #もし単語が辞書に存在していなかったらseedを[BOS]にしてランダムに選択\n",
    "    if not key_candidates:\n",
    "        key_candidates = [key for key in model if key[0] == \"[BOS]\"]                    \n",
    "    \n",
    "    #ランダムにkey選択\n",
    "    m_key = random.choice(key_candidates)\n",
    "    #選択したkeyからqueue生成\n",
    "    queue = deque(list(m_key), n_size)\n",
    "\n",
    "    sentence = \"\"\n",
    "    if m_key[0] != \"[BOS]\":\n",
    "        sentence = \"\".join(m_key)\n",
    "    \n",
    "    while(True):\n",
    "        m_key = tuple(queue)        \n",
    "        \n",
    "        if m_key not in model:\n",
    "            key_candidates = [key for key in model if key[0] == \"[BOS]\"]                    \n",
    "            m_key = random.choice(key_candidates)\n",
    "                \n",
    "        next_word = random.choice(model[m_key])\n",
    "        \n",
    "        if next_word == \"[EOS]\":\n",
    "            sentence_count += 1\n",
    "            \n",
    "            #最大文章数以上なら終了\n",
    "            if sentence_count > max_sentence_num:\n",
    "                break\n",
    "            #最大文章数にみたない場合もランダムで終了\n",
    "            if random.random() < 0.5:\n",
    "                break            \n",
    "                \n",
    "            key_candidates = [key for key in model if key[0] == \"[BOS]\"]    \n",
    "            m_key = random.choice(key_candidates)\n",
    "            queue = deque(list(m_key), n_size)                            \n",
    "            \n",
    "        else:\n",
    "            sentence += next_word\n",
    "            queue.append(next_word)            \n",
    "            \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c57ddc8",
   "metadata": {},
   "source": [
    "※架空のダミーデータでの実行のため、マルコフ連鎖で生成される文章はバリエーションが少ない点に留意。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2dc0425b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ゲーム順調？'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_sentence(self_model_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c2ab98ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ちょっときついな。ちょっときついな。相変わらずゲームばかりします！これほんと、これ、みんなクリアできるんだろうか？'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_sentence(self_model_A, seed=\"今日ご飯食べる？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4611c2e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'最近ゲームばかりした時間でお送りしたね！何やって聞かせている。いやほんと、どうかしてる？ゲームばかりしてリストつくるので少々お待ちを。'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_sentence(self_model_A, seed=\"今日ご飯食べる？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a2ad102d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'すでに実況ゲームもやりたい、今はいかない。'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_sentence(self_model_A, seed=\"今日ご飯食べる？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982a1aec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
